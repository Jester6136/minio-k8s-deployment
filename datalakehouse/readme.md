## Architecture

```
Spark ‚îÄ‚îê
       ‚îú‚îÄ‚îÄ Iceberg ‚Üí Nessie (REST catalog)
Trino ‚îÄ‚îò              ‚Üì
               External MinIO (S3)
```

MinIO endpoints (already running):

* S3 API: `https://api-storage.aiacademy.edu.vn  `
* Console: `https://storage.aiacademy.edu.vn  `
* Bucket: `warehouse`

---

## 1Ô∏è‚É£ Folder Tree

```
datalakehouse/
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ spark/
‚îÇ   ‚îî‚îÄ‚îÄ spark-defaults.conf
‚îî‚îÄ‚îÄ trino/
    ‚îî‚îÄ‚îÄ catalog/
        ‚îî‚îÄ‚îÄ iceberg.properties
```

---

## 2Ô∏è‚É£ Docker Compose

üìÑ `docker-compose.yml`

```yaml
services:

  nessie:
    image: projectnessie/nessie:latest
    container_name: nessie
    ports:
      - "19120:19120"
    environment:
      NESSIE_VERSION_STORE_TYPE: INMEMORY

  trino:
    image: trinodb/trino:latest
    container_name: trino
    ports:
      - "8080:8080"
    volumes:
      - ./trino/catalog:/etc/trino/catalog
    depends_on:
      - nessie

  spark:
    image: apache/spark:3.5.0
    container_name: spark
    command: >
      /opt/spark/bin/spark-class
      org.apache.spark.deploy.master.Master
    volumes:
      - ./spark:/opt/spark/conf
    ports:
      - "7077:7077"
      - "8081:8080"
    depends_on:
      - nessie
```

---

## 3Ô∏è‚É£ Spark Configuration (Iceberg + Nessie + MinIO)

üìÑ `spark/spark-defaults.conf`

```properties
spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions

spark.jars.packages=\
org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.2,\
org.projectnessie:nessie-spark-extensions-3.5_2.12:0.84.0

spark.sql.catalog.nessie=org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.nessie.catalog-impl=org.apache.iceberg.nessie.NessieCatalog
spark.sql.catalog.nessie.uri=http://nessie:19120/api/v1
spark.sql.catalog.nessie.ref=main
spark.sql.catalog.nessie.warehouse=s3://warehouse/
spark.sql.catalog.nessie.io-impl=org.apache.iceberg.aws.s3.S3FileIO

spark.hadoop.fs.s3a.endpoint=https://api-storage.aiacademy.edu.vn  
spark.hadoop.fs.s3a.access.key=YOUR_ACCESS_KEY
spark.hadoop.fs.s3a.secret.key=YOUR_SECRET_KEY
spark.hadoop.fs.s3a.path.style.access=true
spark.hadoop.fs.s3a.connection.ssl.enabled=true
```

---

## 4Ô∏è‚É£ Trino Iceberg Catalog

üìÑ `trino/catalog/iceberg.properties`

```properties
connector.name=iceberg

iceberg.catalog.type=rest
iceberg.rest-catalog.uri=http://nessie:19120/api/v1
iceberg.rest-catalog.ref=main
iceberg.rest-catalog.warehouse=s3://warehouse/

fs.native-s3.enabled=true
s3.endpoint=https://api-storage.aiacademy.edu.vn  
s3.aws-access-key=YOUR_ACCESS_KEY
s3.aws-secret-key=YOUR_SECRET_KEY
s3.path-style-access=true
s3.ssl.enabled=true
```

---

## 5Ô∏è‚É£ Start the Stack

```bash
docker compose down -v
docker compose pull
docker compose up -d
```

---

## 6Ô∏è‚É£ Test the Setup

### Spark (write Iceberg)

```bash
docker exec -it spark /opt/spark/bin/spark-sql
```

```sql
CREATE TABLE nessie.demo.users (
  id INT,
  name STRING
) USING iceberg;

INSERT INTO nessie.demo.users VALUES (1, 'Alice');
```

### Trino (read Iceberg)

Open ‚Üí [http://localhost:8080](http://localhost:8080)

```sql
SELECT * FROM iceberg.demo.users;
```

### MinIO

Check bucket:

```
warehouse/demo/users/
```

---

## ‚úÖ Key Design Decisions

* ‚ùå Bitnami Spark removed (commercial)
* ‚úÖ Apache official Spark image
* ‚úÖ External MinIO (production-grade)
* ‚úÖ Nessie REST catalog (Git-like Iceberg)
* ‚úÖ Iceberg shared by Spark & Trino